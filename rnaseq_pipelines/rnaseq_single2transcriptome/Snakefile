#####################################################################################
###
### Pipeline used to process raw single-end RNAseq reads and align them to a transcriptome using Salmon.
###
######################################################################################

# Load configuration file
configfile: "config/config.yml"

# Detect automatically single-end read samples (only the sample name, not subdirectories)
sample_names,= glob_wildcards("workflow/resources/reads/{sample}.fastq.gz")

#########################
###                   ###
### Collect all rules ###
###                   ###
#########################

rule all:
    input:
        expand("01_trim/{sample}_trim.fastq.gz", sample=sample_names),
        expand("02_rrna_filtered/{sample}.fq.gz", sample=sample_names),
        "00_qc/multiqc.html",
        expand("04_salmon/{sample}/quant.sf", sample=sample_names)

######################
###                ###
### Setting up run ###
###                ###
######################

rule symlink_dbs:
    output:
        kraken2 = directory("tmp/kraken2"),
        rrna = "tmp/rrna_db.fa"
    params: 
        kraken2 = config["kraken2_db"],
        rrna = config["rrna_db"]
    shell:
        """
        ln -sf {params.kraken2} {output.kraken2}
        ln -sf {params.rrna} {output.rrna}
        """

rule sortmerna_install:
    input:
        "tmp/rrna_db.fa"
    output:
        script = "workflow/scripts/bin/sortmerna"
    shell:
        """
        wget https://github.com/biocore/sortmerna/releases/download/v4.3.6/sortmerna-4.3.6-Linux.sh -P workflow/scripts
        cd workflow/scripts
        bash sortmerna-4.3.6-Linux.sh --skip-license
        rm sortmerna-4.3.6-Linux.sh
        """

###########################
###                     ###
### Quality check steps ###
###                     ###
###########################

rule trim:
    input:
       r1 = "workflow/resources/reads/{sample}.fastq.gz"
    output:
       r1 = "01_trim/{sample}_trim.fastq.gz",
       json = "00_qc/{sample}.json"
    log:
       "logs/{sample}_fastp.log"
    params:
        html = "01_trim/{sample}.html",
        quality = 30,
        window = 5
    conda:
       "workflow/envs/fastp.yml"
    threads:
        config["threads"]
    shell:
        """
        fastp \
        -i {input.r1} \
        -o {output.r1} \
        -q {params.quality} \
        -5 \
        -j {output.json} \
        -h {params.html} \
        --cut_front_window_size {params.window} \
        --cut_front_mean_quality {params.quality} \
        -r \
        --cut_right_window_size {params.window} \
        --cut_right_mean_quality {params.quality} \
        --correction \
        --low_complexity_filter \
        -w {threads} \
        > {log} 2>&1
        """

rule fastqc_post_trim:
   input:
       r1 = "01_trim/{sample}_trim.fastq.gz"
   output:
       touch("00_qc/{sample}_post_trim.done")
   log:
       "logs/{sample}_fastqc_post_trim.log"
   params:
       prefix = "00_qc/{sample}"
   threads:
       config["threads"]
   conda:
       "workflow/envs/fastqc.yml"
   shell:
       """
       mkdir -p {params.prefix}
       fastqc -t {threads} {input.r1} --outdir {params.prefix} &> {log} 
       """

rule sortmerna:
    input:
       r1 = "01_trim/{sample}_trim.fastq.gz",
       database = "tmp/rrna_db.fa",
       tool = "workflow/scripts/bin/sortmerna"
    output:
        r1 = "02_rrna_filtered/{sample}.fq.gz"
    log:
        "logs/{sample}_sortmerna.log"
    params:
        outdir = "02_rrna_filtered/{sample}",
        temp_wd = temp("02_rrna_filtered/{sample}_wd")
    shell:
        """
        mkdir -p 02_rrna_filtered/wd
        {input.tool} --ref {input.database} \
                  --reads {input.r1} \
                  --workdir {params.temp_wd} \
                  --fastx \
                  --num_alignments 1 \
                  --other {params.outdir} \
                  > {log} 2>&1
        """

rule kraken2:
    input:
        r1 = "02_rrna_filtered/{sample}.fq.gz"
    output:
        kraken2="03_kraken2_report/{sample}.output.txt",
        kraken2_report="00_qc/{sample}.report.txt"
    log:
        "logs/{sample}_kraken2.log"
    params:
        db = "tmp/kraken2"
    conda: "workflow/envs/kraken2.yml"
    threads: config["threads"]
    shell:
        """
        mkdir -p 03_kraken2_report
        kraken2 --db {params.db} \
        --threads {threads} \
        --output {output.kraken2} \
        --report {output.kraken2_report} \
        {input.r1}
        """

rule kraken2_filter:
    input:
        r1 = "02_rrna_filtered/{sample}.fq.gz",
        kraken2_output = "03_kraken2_report/{sample}.output.txt",
        kraken2_report = "00_qc/{sample}.report.txt"
    output:
        r1 = "03_kraken2_report/{sample}_filtered.fq.gz"
    log: "logs/{sample}_kraken2_filter.log"
    conda: "workflow/envs/kraken2.yml"
    params:
        r1 = "03_kraken2_report/{sample}_filtered.fq"
    shell:
        """
        extract_kraken_reads.py \
        -k {input.kraken2_output} \
        -t  6157 \
        --include-children \
        -r {input.kraken2_report} \
        -s1 {input.r1} \
        --fastq-output \
        -o {params.r1} > {log} 2>&1 
        
        gzip {params.r1}
        """


rule multiqc:
    input:
        expand("00_qc/{sample}.report.txt", sample = sample_names),
        expand("00_qc/{sample}.json",  sample = sample_names),
        expand("04_salmon/{sample}/quant.sf",  sample = sample_names)
    output:
        "00_qc/multiqc.html"
    params:
        name = "multiqc.html"
    conda: "workflow/envs/multiqc.yml"
    log: "logs/multiqc.log"
    shell:
        """
        multiqc --force -d  --filename {params.name} 00_qc/ 04_salmon/ > {log} 2>&1
        mv {params.name} 00_qc/
        """


####################
###              ###
### Read mapping ###
###              ###
####################

rule salmon_index:
    input:
        transcriptome = config["transcriptome"]
    output:
        "04_salmon/salmon_index_done"
    log: "logs/salmon_index.log"
    conda: "workflow/envs/salmon.yml"
    threads: config["threads"]
    shell:
        """
        salmon index -t {input.transcriptome} -i 04_salmon/salmon_index -p {threads} > {log} 2>&1 && touch {output}
        """

rule salmon_quant:
    priority: 1
    input: 
        r1 = "03_kraken2_report/{sample}_filtered.fq.gz",
        index="04_salmon/salmon_index_done"
    output:
        quant = "04_salmon/{sample}/quant.sf",
        log = "00_qc/{sample}/lib_format_counts.json"
    params:
        path = "04_salmon/{sample}",
        prefix = "{sample}"
    log:
        "logs/{sample}_salmon_quant.log"
    threads: config["threads"]
    conda:
        "workflow/envs/salmon.yml"
    shell:
        """
        salmon quant \
        -i 04_salmon/salmon_index \
        -l A \
        -r {input.r1} \
        -p {threads} \
        --validateMappings \
        -o {params.path} > {log} 2>&1

        cp {params.path}/aux_info/meta_info.json 00_qc/{params.prefix}/
        cp {params.path}/lib_format_counts.json {output.log}
       """
